[Colab](https://colab.research.google.com/drive/1dyyTUepjQm2o3gzlotEOj1p4X8mjbCYo?usp=sharing)


|                 | Predicted +    | Predicted -    |
| --------------- | -------------- | -------------- |
| Actual Positive | True Positive  | False Negative |
| Actual Negative | False Positive | True Negative  |
Covid Test:

| Actual     | Predicted + | Predicted - |      |
| ---------- | ----------- | ----------- | ---- |
| Disease    | 531         | 6           | 537  |
| No Disease | 20          | 9443        | 9463 |
| Total      | 551         | 9449        |      |
What is the probability of having covid given a positive Test?
P(disease | +) = (531) / 551 = 96.4 %

Bayes' Rule:
Given B happened(Already Happened) , What is prob of A

$$
P(A|B) = (P(B|A) * P(A) ) /  P(B)
$$
P(False +) = 0.05 => P(+ | no disease)
p(False -) = 0.01 => P(- | disease)
P(disease) = 0.1 => In general Population

P(disease | + test) => P(+ test | disease) * P(disease) / P(+)
P(+) => P(+ | disease) . p(disease) + p(+ | no disease) . p(no disease)
We are expanding Bayes here
68.75%
### Classification use case  
C1, C2, C3...., Ck => Categories

> [!NOTE]
> Because it's computationally very light (no iterative training), Naive Bayes is great for **real-time applications** (e.g., recommendation alerts, fraud alerts).
> 

P(Ck | X1, X2..) = (P(X1, X2, X3..Xn  |  Ck) * P(Ck)) / P(X)

LHS: Ck -Posterior, X feature vector
RHS: Ck - P(Ck) -> Prior,   P(X | Ck) -> Likelihood, P(X) -> Evidence


| Type            | Use Case                                | Class             |
| --------------- | --------------------------------------- | ----------------- |
| `MultinomialNB` | Text classification (word counts)       | `MultinomialNB()` |
| `BernoulliNB`   | Binary features (presence/absence)      | `BernoulliNB()`   |
| `GaussianNB`    | Continuous data (e.g., medical, sensor) | `GaussianNB()`    |
Assumes X1, X2, X3 are independent, 

Doesn't matter if they actually are independent or Not
Works well in Most use cases like Bag Of Words

> [!When to use]
> - Do you need a fast, interpretable model? → ✅ Use Naive Bayes
> - Are you classifying text, emails, or short messages? → ✅ Use Naive Bayes
> - Are your features highly correlated or continuous without Gaussian distribution? → ⚠️ Consider Logistic Regression, SVM, or Random Forest
> - Is accuracy more important than simplicity/speed? → ⚠️ Use more powerful models

