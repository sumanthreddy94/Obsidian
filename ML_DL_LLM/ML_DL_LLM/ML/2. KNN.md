[KNN Colab](https://colab.research.google.com/drive/1dyyTUepjQm2o3gzlotEOj1p4X8mjbCYo?usp=sharing)

Euclidean Distance

$$
d = ((x2-x1) ^ 2 + (y2-y1)^2)^1/2
$$
We determine minimal distance and majority of elements near to the target element.
and We classify that 
KNN works this way:
- It counts how many neighbors belong to each class.
- Assigns the label with the **highest vote**

Choosing how many `n_neighbors`  to look at:
- Small `k` (like 1 or 3): sensitive to noise, may overfit.
- Large `k`: smoother boundary, may under fit.

For **binary classification**, this is the foundation:

|                 | Predicted +    | Predicted -    |
| --------------- | -------------- | -------------- |
| Actual Positive | True Positive  | False Negative |
| Actual Negative | False Positive | True Negative  |
### Evaluation Metrics:

Precision

Of all **Predicted** positive cases, how many did we **correctly predict**?

> [!Precision]
>   
> - High Precision = **few false positives** 
>  - Good when **false positives are costly**



$$
Precision = TP / (TP + FP)
$$

Recall:

Of all **actual** positive cases, how many did we **correctly predict**?

> [!Recall]
> - High Recall = **few false negatives**
> - Good when **missing positives is costly**

$$
Recall (Sensitivity) = TP / (TP + FN)
$$
