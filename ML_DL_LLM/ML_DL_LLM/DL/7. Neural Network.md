[Colab-1](https://colab.research.google.com/drive/1dyyTUepjQm2o3gzlotEOj1p4X8mjbCYo?usp=sharing)
[Colab-2](https://colab.research.google.com/drive/1FtYtO2CE771UrUbnrspY1WBTODSoWNP-?usp=sharing)
Input layer -> Hidden Layer -> Output Layer

Each Layer Node is Neuron
X0, X1, X2..-> Features Input

All features are weighted, w0, w1, w2...

Sum of Weighted features goes into Neuron

z 0  = X0. w0 + X1 . w1 ...

Bias: Shift the Z0 add 5, Subtract 0.5, multiply 2 (Some Bias)


> [!NOTE]
> z0 -->bias + z0 -> z0b -> Neuron -> f(z0b) Activation  function -> Output

The number of weights Wi​ in the **first layer** of a neural network **matches the number of input features**.

Total Trainable parameters is at each layer is, 
For a `Dense(units=n_neurons)` layer with input features = f:

$$
Total Trainable params = f×n_neurons  + n_neurons (for biases)
$$

### Activation Function:
Without Activation Function We get linear model for all possible Combinations.

Activation function introduces Non - Linearity with functions like Sigmoid, Tanh, 
RELU(< 0 is 0, >0 is linear)

### Gradient Descent

Train the model:
We may get Loss, Feed the loss to Model.
L2 Loss function = Mean Squared Error
$$
\text{L2 Loss} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$
L2 Loss Function is a Quadratic y = x^2 format
Loss is low at the Bottom
In order to follow this slope, math have gradient Descent
Basically local Minimum

$$
\nabla
$$
Above is derivative of Loss function, substitute alpha as 0.1 or 0.01 and keep perform below descent recursively.
alpha too large -> Can Overshoot minimum
alpha too -> Training takes more time

$$
\theta := \theta - \alpha \cdot \nabla_\theta L(\theta)
$$


*FYI Gradient Ascent is used for Local maximum*


w0, w1, w2 have different slopes with respect to some values

Each **epoch** runs **many gradient descent iterations** — **one per batch** — and in each iteration:
- The model **modifies the weights w0,w1,w2,…w0​,w1​,w2​,…**
- Based on **the gradients of the loss**
- Toward a **local (or global) minimum** of the loss function

### Back propagation:
> **Backpropagation** is the algorithm that **computes the gradients of the loss function** with respect to each weight and bias in the network, **layer by layer, moving backward** from the output to the input.

This is how the model **knows how to adjust weights** (+ Bias) to reduce loss.

$$
\theta := \theta - \alpha \cdot \nabla_\theta L(\theta)
$$

So we can get new weights for each iteration
$$
\text{Loss}(w_0, w_1, w_2) = \frac{1}{2}(y - \hat{y})^2
$$

Where:

$$
\hat{y} = w_0 x_0 + w_1 x_1 + w_2 x_2 + b
$$


$$
w_i := w_i - \alpha \cdot \frac{\partial \text{Loss}}{\partial w_i}
\quad \text{for all } i = 0, 1, 2, \dots
$$


So after each step:
- w0​ gets slightly updated
- w1 gets slightly updated
- w2 gets slightly updated  
    → All of them move **closer to the values** that minimize the loss




### SUMMARY

So Training = This Loop:

1. Make a prediction (forward pass)
2. Compare it with the real value (compute loss)
3. See which weights caused the error (backpropagation)
4. Adjust those weights just a little (gradient descent)
5. Repeat — **thousands of times** — until the model becomes **really good** at predicting



> [!Intution]
> - More Dense the layer => More Factors/Trends affecting output => More Training time 
> - Sweet spot: Tune dense layer nodes, use overfitting techniques.
> - Gradiant Decent + BackPropagation = Local minimal loss for each w, b curves => best learnt model   
> - We are giving proper weightage and bias to all factors/trends that can influence the output.
>
